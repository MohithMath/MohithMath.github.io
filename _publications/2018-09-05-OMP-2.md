---
title: "Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds"
collection: publications
permalink: /publication/2018-09-05-OMP-2
excerpt: 'We provide a formulation of empirical Bayes Atchad√© to tune the hyperparameters of priors used in Bayesian set-up of collaborative filter.'
date: 2018-09-05
venue: 'NIPS 2018'
authors: 'Raghav Somani, Chirag Gupta, Praneeth Netrapalli, Prateek Jain'

---
This paper studies the problem of sparse regression where the goal is to learn a sparse vector that best optimizes a given objective function. Under the assumption that the objective function satisfies restricted strong convexity (RSC), we analyze *Orthogonal Matching Pursuit (OMP)*, a greedy algorithm that is used heavily in applications, and obtain support recovery result as well as a tight generalization error bound for OMP. Furthermore, we obtain lower bounds for OMP, showing that both our results on support recovery and generalization error are tight up to logarithmic factors. To the best of our knowledge, these support recovery and generalization bounds are the first such matching upper and lower bounds (up to logarithmic factors) for *any* sparse regression algorithm under the RSC assumption.